{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3d9b04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T14:52:54.483881Z",
     "iopub.status.busy": "2024-04-10T14:52:54.483065Z",
     "iopub.status.idle": "2024-04-10T14:53:07.010344Z",
     "shell.execute_reply": "2024-04-10T14:53:07.009294Z",
     "shell.execute_reply.started": "2024-04-10T14:52:54.483847Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2024-04-10T15:51:21.268387",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "from glob import glob\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "from scipy.stats import entropy\n",
    "from scipy.signal import butter, lfilter, freqz\n",
    "from contextlib import contextmanager\n",
    "from collections import defaultdict, Counter\n",
    "# from kaggle_kl_div import score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "# import cv2\n",
    "# from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "import torchvision.models as models\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, OneCycleLR, CosineAnnealingLR, CosineAnnealingWarmRestarts\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torchvision.transforms import v2\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "# import albumentations as A\n",
    "# from albumentations import (Compose, Normalize, Resize, RandomResizedCrop, HorizontalFlip, VerticalFlip, ShiftScaleRotate, Transpose)\n",
    "# from albumentations.pytorch import ToTensorV2\n",
    "# from albumentations import ImageOnlyTransform\n",
    "# import timm\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "from matplotlib import pyplot as plt\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a17d69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T14:53:13.577202Z",
     "iopub.status.busy": "2024-04-10T14:53:13.576053Z",
     "iopub.status.idle": "2024-04-10T14:53:13.587409Z",
     "shell.execute_reply": "2024-04-10T14:53:13.586374Z",
     "shell.execute_reply.started": "2024-04-10T14:53:13.577146Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    version = 2\n",
    "    criterion = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "    num_workers = 1\n",
    "    model_name = 'resnet1d_gru'\n",
    "    optimizer='AdamW'\n",
    "    epochs = 10\n",
    "    lr = 1e-3\n",
    "    batch_size = 64\n",
    "    eval_every = 1000\n",
    "    target_cols = ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\n",
    "    num_class = 6\n",
    "    n_fold = 5\n",
    "    # trn_fold = [0, 1, 2, 3, 4]\n",
    "    trn_fold = [0, 1]\n",
    "    PATH = '/kaggle/input/hms-harmful-brain-activity-classification/'\n",
    "    EEG_FILE = '/kaggle/input/brain-eegs/eegs.npy'\n",
    "    eeg_features = ['Fp1','T3','C3','O1','Fp2','C4','T4','O2']\n",
    "    feature_to_index = {x:i for i, x in enumerate(eeg_features)}\n",
    "    map_features = [\n",
    "        (\"Fp1\", \"T3\"),\n",
    "        (\"T3\", \"O1\"),\n",
    "        (\"Fp1\", \"C3\"),\n",
    "        (\"C3\", \"O1\"),\n",
    "        (\"Fp2\", \"C4\"),\n",
    "        (\"C4\", \"O2\"),\n",
    "        (\"Fp2\", \"T4\"),\n",
    "        (\"T4\", \"O2\"),\n",
    "    ]\n",
    "    num_features = len(map_features)\n",
    "    in_channels = 8\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68c83fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T14:53:19.413477Z",
     "iopub.status.busy": "2024-04-10T14:53:19.413113Z",
     "iopub.status.idle": "2024-04-10T14:53:20.335285Z",
     "shell.execute_reply": "2024-04-10T14:53:20.334370Z",
     "shell.execute_reply.started": "2024-04-10T14:53:19.413449Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(CFG.PATH + '/train.csv')\n",
    "TARGETS = train.columns[-6:]\n",
    "print(train.head())\n",
    "print('Train shape:', train.shape )\n",
    "print('Targets', list(TARGETS))\n",
    "\n",
    "train['total_evaluators'] = train[TARGETS].sum(axis=1)\n",
    "\n",
    "train_uniq = train.drop_duplicates(subset=['eeg_id'] + list(TARGETS))\n",
    "\n",
    "print(f'There are {train.patient_id.nunique()} patients in the training data.')\n",
    "print(f'There are {train.eeg_id.nunique()} EEG IDs in the training data.')\n",
    "print(f'There are {train_uniq.shape[0]} unique eeg_id + votes in the training data.')\n",
    "\n",
    "train_uniq.eeg_id.value_counts().value_counts().plot(kind='bar', title=f'Distribution of Count of EEG w Unique Vote: '\n",
    "                                                                    f'{train_uniq.shape[0]} examples');\n",
    "train = train_uniq.copy()\n",
    "y_data = train[TARGETS].values +  1/6 # Regularization value\n",
    "y_data = y_data / y_data.sum(axis=1,keepdims=True)\n",
    "train[TARGETS] = y_data\n",
    "\n",
    "train['target'] = train['expert_consensus']\n",
    "train = train.reset_index(drop=True)\n",
    "\n",
    "del train_uniq\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0cc52e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T14:53:24.504550Z",
     "iopub.status.busy": "2024-04-10T14:53:24.503871Z",
     "iopub.status.idle": "2024-04-10T14:53:24.733058Z",
     "shell.execute_reply": "2024-04-10T14:53:24.732214Z",
     "shell.execute_reply.started": "2024-04-10T14:53:24.504519Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(train['total_evaluators'], bins=10, color='blue', edgecolor='black')\n",
    "plt.title('Histogram of Total Evaluators')\n",
    "plt.xlabel('Total Evaluators')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d5934b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T14:54:01.531911Z",
     "iopub.status.busy": "2024-04-10T14:54:01.531211Z",
     "iopub.status.idle": "2024-04-10T14:55:42.024332Z",
     "shell.execute_reply": "2024-04-10T14:55:42.023174Z",
     "shell.execute_reply.started": "2024-04-10T14:54:01.531867Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_eegs = np.load(CFG.EEG_FILE, allow_pickle=True).item()\n",
    "eeg_ids = train.eeg_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022ee622",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T14:56:11.757115Z",
     "iopub.status.busy": "2024-04-10T14:56:11.756341Z",
     "iopub.status.idle": "2024-04-10T14:56:11.784824Z",
     "shell.execute_reply": "2024-04-10T14:56:11.783693Z",
     "shell.execute_reply.started": "2024-04-10T14:56:11.757083Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gkf = GroupKFold(n_splits=CFG.n_fold)\n",
    "\n",
    "train[\"fold\"] = -1\n",
    "\n",
    "for fold_id, (_, val_idx) in enumerate(\n",
    "    gkf.split(train, y=train[\"target\"], groups=train[\"patient_id\"])\n",
    "):\n",
    "    train.loc[val_idx, \"fold\"] = fold_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e153e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T14:56:13.348420Z",
     "iopub.status.busy": "2024-04-10T14:56:13.347457Z",
     "iopub.status.idle": "2024-04-10T14:56:13.364734Z",
     "shell.execute_reply": "2024-04-10T14:56:13.363650Z",
     "shell.execute_reply.started": "2024-04-10T14:56:13.348386Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.signal import butter, lfilter\n",
    "\n",
    "def quantize_data(data, classes):\n",
    "    mu_x = mu_law_encoding(data, classes)\n",
    "    return mu_x#quantized\n",
    "\n",
    "def mu_law_encoding(data, mu):\n",
    "    mu_x = np.sign(data) * np.log(1 + mu * np.abs(data)) / np.log(mu + 1)\n",
    "    return mu_x\n",
    "\n",
    "def mu_law_expansion(data, mu):\n",
    "    s = np.sign(data) * (np.exp(np.abs(data) * np.log(mu + 1)) - 1) / mu\n",
    "    return s\n",
    "\n",
    "def butter_lowpass_filter(data, cutoff_freq=20, sampling_rate=200, order=4):\n",
    "    nyquist = 0.5 * sampling_rate\n",
    "    normal_cutoff = cutoff_freq / nyquist\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    filtered_data = lfilter(b, a, data, axis=0)\n",
    "    return filtered_data\n",
    "\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(\n",
    "        self, df: pd.DataFrame, config, mode: str = 'train',\n",
    "        eegs: Dict[int, np.ndarray] = all_eegs, downsample: int = None\n",
    "    ): \n",
    "        self.df = df\n",
    "        self.config = config\n",
    "        self.mode = mode\n",
    "        self.eegs = eegs\n",
    "        self.downsample = downsample\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Length of dataset.\n",
    "        \"\"\"\n",
    "        return len(self.df)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Get one item.\n",
    "        \"\"\"\n",
    "        X, y_prob = self.__data_generation(index)\n",
    "        if self.downsample is not None:\n",
    "            X = X[::self.downsample,:]\n",
    "        output = {\n",
    "            \"eeg\": torch.tensor(X, dtype=torch.float32),\n",
    "            \"labels\": torch.tensor(y_prob, dtype=torch.float32)\n",
    "        }\n",
    "        return output\n",
    "                        \n",
    "    def __data_generation(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        X = np.zeros((10_000, CFG.num_features), dtype='float32')\n",
    "        y = np.zeros(CFG.num_class, dtype='float32')\n",
    "        data = self.eegs[row.eeg_id]\n",
    "\n",
    "        # === Feature engineering ===\n",
    "        feature_to_index = CFG.feature_to_index\n",
    "        # X[:,0] = data[:,feature_to_index['Fp1']] - data[:,feature_to_index['T3']]\n",
    "        # X[:,1] = data[:,feature_to_index['T3']] - data[:,feature_to_index['O1']]\n",
    "\n",
    "        # X[:,2] = data[:,feature_to_index['Fp1']] - data[:,feature_to_index['C3']]\n",
    "        # X[:,3] = data[:,feature_to_index['C3']] - data[:,feature_to_index['O1']]\n",
    "\n",
    "        # X[:,4] = data[:,feature_to_index['Fp2']] - data[:,feature_to_index['C4']]\n",
    "        # X[:,5] = data[:,feature_to_index['C4']] - data[:,feature_to_index['O2']]\n",
    "\n",
    "        # X[:,6] = data[:,feature_to_index['Fp2']] - data[:,feature_to_index['T4']]\n",
    "        # X[:,7] = data[:,feature_to_index['T4']] - data[:,feature_to_index['O2']]\n",
    "\n",
    "        for i, p in enumerate(CFG.map_features):\n",
    "            X[:, i] = data[:, feature_to_index[p[0]]] - data[:, feature_to_index[p[1]]]\n",
    "\n",
    "        # === Standarize ===\n",
    "        X = np.clip(X,-1024, 1024)\n",
    "        X = np.nan_to_num(X, nan=0) / 32.0\n",
    "\n",
    "        # === Butter Low-pass Filter ===\n",
    "        X = butter_lowpass_filter(X)\n",
    "        if self.mode != 'test':\n",
    "            y_prob = row[self.config.target_cols].values.astype(np.float32)\n",
    "        return X, y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03c80fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T14:56:15.933159Z",
     "iopub.status.busy": "2024-04-10T14:56:15.932377Z",
     "iopub.status.idle": "2024-04-10T14:56:15.971208Z",
     "shell.execute_reply": "2024-04-10T14:56:15.970229Z",
     "shell.execute_reply.started": "2024-04-10T14:56:15.933125Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = EEGDataset(train, CFG, mode=\"train\")\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=CFG.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=CFG.num_workers, pin_memory=True, drop_last=True\n",
    ")\n",
    "output = train_dataset[0]\n",
    "X, y = output[\"eeg\"], output[\"labels\"]\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583f2a77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T14:56:18.121932Z",
     "iopub.status.busy": "2024-04-10T14:56:18.121234Z",
     "iopub.status.idle": "2024-04-10T14:56:18.145286Z",
     "shell.execute_reply": "2024-04-10T14:56:18.144256Z",
     "shell.execute_reply.started": "2024-04-10T14:56:18.121888Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class ResNet_1D_Block(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, downsampling, drop_prob):\n",
    "        super(ResNet_1D_Block, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm1d(num_features=in_channels)\n",
    "        self.relu = nn.ReLU(inplace=False)\n",
    "        self.dropout = nn.Dropout(p=drop_prob, inplace=False)\n",
    "        self.conv1 = nn.Conv1d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size,\n",
    "                               stride=stride, padding=padding, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(num_features=out_channels)\n",
    "        self.conv2 = nn.Conv1d(in_channels=out_channels, out_channels=out_channels, kernel_size=kernel_size,\n",
    "                               stride=stride, padding=padding, bias=False)\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=2, stride=2, padding=0)\n",
    "        self.downsampling = downsampling\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.bn1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.conv1(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        out = self.maxpool(out)\n",
    "        identity = self.downsampling(x)\n",
    "\n",
    "        out += identity\n",
    "        return out\n",
    "\n",
    "\n",
    "class EEGNet(nn.Module):\n",
    "\n",
    "    def __init__(self, kernels, in_channels=20, fixed_kernel_size=17, num_classes=6, drop_prob=.1):\n",
    "        super(EEGNet, self).__init__()\n",
    "        self.kernels = kernels\n",
    "        self.planes = 24\n",
    "        self.parallel_conv = nn.ModuleList()\n",
    "        self.in_channels = in_channels\n",
    "        \n",
    "        for i, kernel_size in enumerate(list(self.kernels)):\n",
    "            sep_conv = nn.Conv1d(in_channels=in_channels, out_channels=self.planes, kernel_size=(kernel_size),\n",
    "                               stride=1, padding=0, bias=False,)\n",
    "            self.parallel_conv.append(sep_conv)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(num_features=self.planes)\n",
    "        self.relu = nn.ReLU(inplace=False)\n",
    "        self.conv1 = nn.Conv1d(in_channels=self.planes, out_channels=self.planes, kernel_size=fixed_kernel_size,\n",
    "                               stride=2, padding=2, bias=False)\n",
    "        self.block = self._make_resnet_layer(kernel_size=fixed_kernel_size, stride=1, padding=fixed_kernel_size//2, drop_prob=drop_prob)\n",
    "        self.bn2 = nn.BatchNorm1d(num_features=self.planes)\n",
    "        self.avgpool = nn.AvgPool1d(kernel_size=6, stride=6, padding=2)\n",
    "        self.rnn = nn.GRU(input_size=self.in_channels, hidden_size=128, num_layers=1, bidirectional=True)\n",
    "        self.fc = nn.Linear(in_features=424, out_features=num_classes)\n",
    "\n",
    "    def _make_resnet_layer(self, kernel_size, stride, blocks=9, padding=0, drop_prob=.1):\n",
    "        layers = []\n",
    "        downsample = None\n",
    "        base_width = self.planes\n",
    "\n",
    "        for i in range(blocks):\n",
    "            downsampling = nn.Sequential(\n",
    "                    nn.MaxPool1d(kernel_size=2, stride=2, padding=0)\n",
    "                )\n",
    "            layers.append(ResNet_1D_Block(in_channels=self.planes, out_channels=self.planes, kernel_size=kernel_size,\n",
    "                                       stride=stride, padding=padding, downsampling=downsampling, drop_prob=drop_prob))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "    def extract_features(self, x):\n",
    "        # x : B=64 x T=10_000 x C=8\n",
    "        x = x.permute(0, 2, 1)      # -> B x C x T\n",
    "        out_sep = []\n",
    "\n",
    "        for i in range(len(self.kernels)):\n",
    "            sep = self.parallel_conv[i](x)\n",
    "            out_sep.append(sep)\n",
    "\n",
    "        out = torch.cat(out_sep, dim=2)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv1(out)  \n",
    "\n",
    "        out = self.block(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.avgpool(out)  \n",
    "        \n",
    "        out = out.reshape(out.shape[0], -1)  \n",
    "        rnn_out, _ = self.rnn(x.permute(0, 2, 1))\n",
    "        new_rnn_h = rnn_out[:, -1, :]  \n",
    "        \n",
    "\n",
    "        new_out = torch.cat([out, new_rnn_h], dim=1) \n",
    "        return new_out\n",
    "    \n",
    "    def forward(self, x, targets=None):\n",
    "        out = self.extract_features(x)\n",
    "        logits = self.fc(out)  \n",
    "        \n",
    "        loss = None\n",
    "        if targets is not None:\n",
    "            loss = CFG.criterion(F.log_softmax(logits, dim=1), targets)\n",
    "\n",
    "        return logits, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f512afa8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T14:56:21.474006Z",
     "iopub.status.busy": "2024-04-10T14:56:21.473391Z",
     "iopub.status.idle": "2024-04-10T14:56:22.193298Z",
     "shell.execute_reply": "2024-04-10T14:56:22.192457Z",
     "shell.execute_reply.started": "2024-04-10T14:56:21.473972Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "iot = torch.randn(2, 10000, 8)#.cuda()\n",
    "model = EEGNet(kernels=[3,5,7,9], in_channels=CFG.in_channels, fixed_kernel_size=5, num_classes=CFG.num_class, drop_prob=.2)\n",
    "output, loss = model(iot)\n",
    "print(\"{:.1f}M parameters\".format(sum([p.numel() for p in model.parameters()])/1e6))\n",
    "print(output.shape)\n",
    "\n",
    "del iot, model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f522ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T15:04:16.245656Z",
     "iopub.status.busy": "2024-04-10T15:04:16.245005Z",
     "iopub.status.idle": "2024-04-10T15:04:16.249796Z",
     "shell.execute_reply": "2024-04-10T15:04:16.248886Z",
     "shell.execute_reply.started": "2024-04-10T15:04:16.245624Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.mkdir('./models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d2914c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T15:04:38.723223Z",
     "iopub.status.busy": "2024-04-10T15:04:38.722668Z",
     "iopub.status.idle": "2024-04-10T15:04:38.737426Z",
     "shell.execute_reply": "2024-04-10T15:04:38.736360Z",
     "shell.execute_reply.started": "2024-04-10T15:04:38.723191Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "@torch.no_grad()\n",
    "def eval(model, data_loader, eval_iters=5):\n",
    "    model.eval()\n",
    "    lossi = []\n",
    "    for step, batch in enumerate(data_loader):\n",
    "        eeg, labels = batch['eeg'].to(device), batch['labels'].to(device)\n",
    "        _, loss = model(eeg, labels)\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            loss = loss.mean()\n",
    "        lossi.append(loss.item())\n",
    "        if step > eval_iters:\n",
    "            break\n",
    "    return np.mean(lossi)\n",
    "\n",
    "\n",
    "# A minimal training function\n",
    "def train_loop(fold):\n",
    "\n",
    "    train_folds = train[(train['fold'] != fold) & (train['total_evaluators'] >= 5)].reset_index(drop=True)\n",
    "    valid_folds = train[(train['fold'] == fold)].reset_index(drop=True)\n",
    "\n",
    "    train_dataset = EEGDataset(train_folds, CFG, mode=\"train\")\n",
    "    valid_dataset = EEGDataset(valid_folds, CFG, mode=\"train\")\n",
    "\n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                              batch_size=CFG.batch_size,\n",
    "                              shuffle=True,\n",
    "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n",
    "    valid_loader = DataLoader(valid_dataset,\n",
    "                              batch_size=CFG.batch_size,\n",
    "                              shuffle=True,\n",
    "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
    "    \n",
    "    #==== MODEL ===\n",
    "    model = EEGNet(kernels=[3,5,7,9], \n",
    "                   in_channels=CFG.in_channels, \n",
    "                   fixed_kernel_size=5, \n",
    "                   num_classes=CFG.num_class,\n",
    "                   drop_prob=.1)\n",
    "    model.to(device)\n",
    "    model = nn.DataParallel(model)\n",
    "    optim = torch.optim.AdamW(model.parameters())\n",
    "    val_loss = 0.0\n",
    "\n",
    "    for epoch in range(CFG.epochs):\n",
    "        model.train()\n",
    "        with tqdm(train_loader, unit='batches') as tepoch:\n",
    "            for batch in tepoch:\n",
    "                tepoch.set_description(f\"Epoch {epoch+1}\")\n",
    "                eeg, labels = batch['eeg'].to(device), batch['labels'].to(device)\n",
    "                optim.zero_grad()\n",
    "                logits, loss = model(eeg, labels)\n",
    "                \n",
    "                if torch.cuda.device_count() > 1:\n",
    "                    loss = loss.mean()\n",
    "                \n",
    "                loss.backward()\n",
    "                optim.step()\n",
    "\n",
    "                tepoch.set_postfix(loss=loss.item())\n",
    "                \n",
    "        print(f\"After epoch {epoch+1}, val loss : {eval(model, valid_loader, eval_iters=10):.2f}\")\n",
    "    \n",
    "    torch.save(model.state_dict(), f\"./models/ver{CFG.version}_fold{fold}.pt\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236d7420",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T15:04:41.684970Z",
     "iopub.status.busy": "2024-04-10T15:04:41.684229Z",
     "iopub.status.idle": "2024-04-10T15:14:42.728424Z",
     "shell.execute_reply": "2024-04-10T15:14:42.727219Z",
     "shell.execute_reply.started": "2024-04-10T15:04:41.684938Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for fold in CFG.trn_fold:\n",
    "    print(f\"#========== Fold {fold} ==========\")\n",
    "    train_loop(fold)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 7469972,
     "sourceId": 59093,
     "sourceType": "competition"
    },
    {
     "datasetId": 4317718,
     "sourceId": 7465251,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30683,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-10T15:51:17.044077",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}